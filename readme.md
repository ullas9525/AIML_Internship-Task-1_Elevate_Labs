# Data Cleaning & Preprocessing:-

## ğŸ“Œ Overview

This project focuses on converting the **Titanic dataset** from its raw form into a **machineâ€‘learningâ€‘ready format** by performing systematic **data cleaning and preprocessing techniques** in a productionâ€‘style Python pipeline.

The goal of this task is to demonstrate core realâ€‘world preprocessing skills including:

- Handling missing values
- Encoding categorical variables
- Scaling numerical features
- Visualizing outliers and correlations
- Exporting a fully cleaned dataset

---

## ğŸ§  Project Workflow



1. Load and inspect dataset
2. Identify and handle missing values (median/mode/drop)
3. Encode categorical features using Oneâ€‘Hot Encoding
4. Standardize numerical features with Standard Scaler
5. Generate visualizations for data understanding
6. Export cleaned dataset for ML model usage

---

## ğŸ“‚ Folder Structure

```
AIML_INTERNSHIP_TASK_1_ELEVATE_LABS
â”‚
â”œâ”€â”€ Dataset
â”‚     â””â”€â”€ Titanic-Dataset.csv
â”‚
â”œâ”€â”€ Output
â”‚     â”œâ”€â”€ cleaned_titanic_dataset.csv
â”‚     â”œâ”€â”€ boxplots_numerical_features.png
â”‚     â”œâ”€â”€ correlation_heatmap.png
â”‚     â””â”€â”€ survival_rate_by_sex.png
â”‚
â””â”€â”€ titanic_preprocessing.py
```

---

## ğŸ” Visual Results (Screenshots)

| Visualization       | Description                                              |
| ------------------- | -------------------------------------------------------- |
| Box plots           | Detects outliers in numerical features                   |
| Heat map            | Shows correlation among all numerical & encoded features |
| Survival Rate Chart | Reveals genderâ€‘based survival differences                |

All screenshots are inside the **Output** folder.

---

## ğŸ›  Tech Stack

| Component | Technology                                       |
| --------- | ------------------------------------------------ |
| Language  | Python                                           |
| Libraries | Pandas, NumPy, Matplotlib, Seaborn, Scikitâ€‘Learn |
| IDE       | Visual Studio Code                               |

---

## ğŸ“¦ Requirements

Install dependencies before running the script:

```
pip install pandas numpy matplotlib seaborn scikit-learn
```

---

## â–¶ Running the Script

Make sure the dataset is inside the **Dataset** folder. Then run:

```
python titanic_preprocessing.py
```

After execution, cleaned data and visual outputs will appear inside the **Output** folder.

---

## ğŸ“Œ Outcome

The final cleaned dataset contains: âœ” zero missing values âœ” all features numeric (no strings) âœ” scaled numerical data âœ” suitable for ML algorithms like Logistic Regression, SVM, Random Forest, etc.

---

## ğŸ‘¤ Author

**Name:**Â Ullas B R,Â **Role:** AIML Internship Participant â€” Elevate Labs,Â **Task 1:** Data Cleaning & Preprocessing

---

## â­ Final Note

This project demonstrates endâ€‘toâ€‘end preprocessing in a **real deploymentâ€‘style structure**, ensuring reproducibility and engineeringâ€‘level data preparation. Feel free to explore, modify, and build ML models on top of this cleaned dataset.

